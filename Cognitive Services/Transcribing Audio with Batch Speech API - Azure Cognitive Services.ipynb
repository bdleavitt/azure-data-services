{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribing Audio Using the Azure Speech Service - Batch APIs and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Steps\n",
    "* Get a blob SAS URI that you can pass to the API\n",
    "* Submit request.\n",
    "* Wait for transcription to be completed (check status)\n",
    "* Download completed transactions\n",
    "* Combine files\n",
    "* Cleanup / Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you'll need: \n",
    "* An Azure subscription\n",
    "* An Azure Speech service instance provisioned (Note: [needs to be in the standard pricing tier](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/batch-transcription#subscription-key), free tier doesn't currently work with the Batch API)\n",
    "* A Speech service API key\n",
    "* Audio file uploaded to an Azure Blob Storage account. See [supported formats here](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/batch-transcription#supported-formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Step: Generate SAS URI for Audio File in Blob Storage\n",
    "The Batch API service needs to be able to access the audio files you have in blob storage. One way to do that is to make your blobs publicly accessible. But, if your audio is sensitive, a better way to do that is through signed secure URL calls a SAS (shared access signature). This will let you grant access for a limited amount of time and from a restricted IPs. \n",
    "\n",
    "To do this from the Azure portal,\n",
    "1. navigate to the blob storage account and container where your audio is stored. \n",
    "2. right-click on the audio file you'd like to trasncribe. \n",
    "3. select \"Generate SAS\" \n",
    "4. in the pane that opens, set the permissions to \"Read\". The other defaults should be fine for the purposes of this demo. \n",
    "5. Click \"Generate blob SAS token and URL\" \n",
    "6. Copy the Blob SAS URL and save for upcoming steps.\n",
    "\n",
    "_Note: if you are transcribing audio at scale or in a production system, you'll likely want to automate this step. {TODO: insert link to helpful documentation}_\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit your Audio File for Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_sas_url = 'your_blob_sas_url'\n",
    "speech_service_region = 'your_speech_service_region' ## i.e. eastus2\n",
    "speech_service_key = 'your_speech_service_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "speech_batch_url = \"https://{}.cris.ai/api/speechtotext/v2.0/transcriptions\".format(speech_service_region)\n",
    "\n",
    "headers = {\n",
    "    \"Ocp-Apim-Subscription-Key\": speech_service_key, \n",
    "    \"Content-Type\":\"application/json\"\n",
    "}\n",
    "\n",
    "body = {\n",
    "  \"recordingsUrl\": audio_sas_url,\n",
    "  \"models\": [],\n",
    "  \"locale\": \"en-US\",\n",
    "  \"name\": \"FileNameOrSomethingHere\",\n",
    "  \"description\": \"Audio Transcription Submitted from BDL Jupyter Notebook\",\n",
    "  \"properties\": {\n",
    "    \"ProfanityFilterMode\": \"Masked\",\n",
    "    \"PunctuationMode\": \"DictatedAndAutomatic\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(url = speech_batch_url, headers = headers, data = json.dumps(body))\n",
    "\n",
    "## Check Status of Response\n",
    "if r.status_code == 202:\n",
    "    submission_url = r.headers['Operation-Location']\n",
    "    print(\"Audio sumbitted for processing.\")\n",
    "    print(\"Check status of this submission at {}\".format(submission_url))\n",
    "    \n",
    "else: \n",
    "    print(\"There was an error submitting audio for processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on Transcription Status\n",
    "The batch API is not intended to provide an immediate response. Instead, requests are queued and processed over time.\n",
    "\n",
    "The response header of the submission contains a URL with an ID for the job, which can be used to to check the status and get download links for the transcription once complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r2 = requests.get(url=submission_url, headers = headers)\n",
    "transcript_info = json.loads(r2.content)\n",
    "transcript_status = transcript_info['status']\n",
    "transcript_id = transcript_info['id']\n",
    "\n",
    "print(\"Transcription ID# {} Status is {}\".format(transcript_id, transcript_status))\n",
    "if transcript_status == \"Succeeded\":\n",
    "    print(\"Transcripts can be downloaded: \")\n",
    "    for key, value in transcript_info['resultsUrls'].items():\n",
    "        print(key + \" : \" + value)\n",
    "elif transcript_status == \"NotStarted\":\n",
    "    print(\"Transcription has not completed. Please check again later.\")\n",
    "elif transcript_status == \"Running\":\n",
    "    print(\"The submitted transcript is running. Check back soon.\")\n",
    "else:\n",
    "    print(\"There appears to have been some sort of issue with the transcription. {}\".format(r2.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the transcription status is \"Complete\", you can proceed to the next step. In my experience this usually happens within a few minutes to an hour of submission. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Completed Transcription\n",
    "If you upload stereo audio, each channel will be processed into a separate transcript. Mono audio is processed into the same file. \n",
    "\n",
    "The result format is a JSON document that displays the various utterances of the file and their duration and offset. Each utterance is given a confidence score. \n",
    "\n",
    "You can iterate through the JSON transcript files to prepare a block of text that can be submitted to other services for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each channel, download the JSON transcript\n",
    "for key, value in transcript_info['resultsUrls'].items():\n",
    "    transcript = json.loads(requests.get(value).content)\n",
    "    \n",
    "    ## Then, combine the JSON results into a block of text. \n",
    "    full_text = \"\"\n",
    "    for t in transcript[\"AudioFileResults\"][0][\"SegmentResults\"]:\n",
    "        full_text += t['NBest'][0]['Display']\n",
    "    \n",
    "    print(\"Transcript for {}: \\r\\n {}\".format(key, full_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "You may wish to clean up the items you've submitted to the service by issuing the \"Delete\" command to the endpoint with the ID of the submitted transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.delete(url=speech_batch_url+\"/\"+transcript_id, headers=headers)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "Once you've gotten your audio transcript, you can do all kinds of fun things such as performing various text analytics tasks using the Azure Text API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References: \n",
    "[Batch Transcription (REST) Documentation](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/batch-transcription)\n",
    "\n",
    "[Custom Speech API Swagger Documentation](https://eastus2.cris.ai/swagger/ui/index#/Custom%20Speech%20transcriptions%3A/CreateTranscription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
